---

# Part 6 â€“ Game Playing: Minimax & Alpha-Beta Pruning

---

## ðŸ”¹ Why Game Playing in AI?

* Many real-world problems can be seen as **competitive environments**.
* Games like **Chess, Checkers, Go, Tic-Tac-Toe** â†’ test AI reasoning & strategy.
* AI must:

  1. **Plan ahead** (search).
  2. **Handle uncertainty** (opponentâ€™s moves).
  3. **Act optimally** under competition.

---

## ðŸ”¹ Game Search Problems

A game is modeled as a **search tree**:

* **States** â†’ configurations of the board.
* **Initial state** â†’ starting position.
* **Players** â†’ MAX (AI) & MIN (opponent).
* **Actions** â†’ legal moves.
* **Transition model** â†’ how moves change state.
* **Terminal test** â†’ game over?
* **Utility function (payoff)** â†’ win = +1, lose = -1, draw = 0 (simplest case).

---

## ðŸ”¹ Minimax Algorithm

* **Idea**:

  * MAX player tries to **maximize score**.
  * MIN player tries to **minimize score**.
* AI assumes opponent plays optimally.

### Pseudocode

```
function MINIMAX(state, depth, maximizingPlayer):
    if depth == 0 or state is terminal:
        return utility(state)
    
    if maximizingPlayer:
        maxEval = -âˆž
        for each child in successors(state):
            eval = MINIMAX(child, depth-1, false)
            maxEval = max(maxEval, eval)
        return maxEval
    else:
        minEval = +âˆž
        for each child in successors(state):
            eval = MINIMAX(child, depth-1, true)
            minEval = min(minEval, eval)
        return minEval
```

---

## ðŸ”¹ Example â€“ Tic-Tac-Toe

* AI checks all possible future moves.
* Assigns scores:

  * Win = +1
  * Lose = -1
  * Draw = 0
* Chooses move that maximizes AIâ€™s final outcome.

---

## ðŸ”¹ Problem with Minimax

* Game trees are **huge**.
* Example: Chess â‰ˆ 10^120 possible states (too large!).
* NaÃ¯ve Minimax is infeasible.

---

## ðŸ”¹ Alpha-Beta Pruning

* Optimized Minimax.
* **Prunes branches** that cannot affect final decision.
* Maintains two values:

  * **Î± (alpha)** â†’ best value MAX can guarantee.
  * **Î² (beta)** â†’ best value MIN can guarantee.
* If branch is worse than Î± or Î², stop exploring.

### Pseudocode

```
function ALPHA-BETA(state, depth, Î±, Î², maximizingPlayer):
    if depth == 0 or state is terminal:
        return utility(state)

    if maximizingPlayer:
        value = -âˆž
        for each child in successors(state):
            value = max(value, ALPHA-BETA(child, depth-1, Î±, Î², false))
            Î± = max(Î±, value)
            if Î² <= Î±:
                break   // prune
        return value
    else:
        value = +âˆž
        for each child in successors(state):
            value = min(value, ALPHA-BETA(child, depth-1, Î±, Î², true))
            Î² = min(Î², value)
            if Î² <= Î±:
                break   // prune
        return value
```

---

## ðŸ”¹ Benefits of Alpha-Beta

* Same result as Minimax.
* Explores far fewer nodes.
* **Best case**: Cuts search space in half.
* Enables deeper lookahead in games.

---

## ðŸ”¹ Heuristics in Game Search

* Depth is limited â†’ cannot search to end in big games.
* Use **heuristic evaluation functions**:

  * Chess â†’ piece values, board control, king safety.
  * Tic-Tac-Toe â†’ number of 2-in-a-rows.
* These functions approximate the "goodness" of a state.

---

## ðŸ”¹ Example Walkthrough

Tic-Tac-Toe with depth limit:

1. AI = MAX, Opponent = MIN.
2. Expand tree up to 2 levels.
3. Apply heuristic evaluation at leaf nodes.
4. Backpropagate scores using Minimax/Alpha-Beta.
5. AI chooses move with best score.

---

## ðŸ”¹ Game Tree Illustration (simplified)

```
        MAX
       /   \
     MIN   MIN
    /  \   /  \
   +1  -1  0   +1
```

* MAX picks left branch â†’ worst case is +1.

---

## ðŸ”¹ Complexity

* Without pruning: O(b^d)
* With pruning: O(b^(d/2)) (in best case)
* b = branching factor, d = depth.

---

## ðŸ”¹ Applications

1. **Classic board games** â€“ Chess, Checkers, Go.
2. **Video games AI** â€“ decision-making for NPCs.
3. **Strategic planning** â€“ military simulations.
4. **Business competition models** â€“ bidding, auctions.

---

## ðŸ”¹ Class Activities

1. **Tic-Tac-Toe Demo** â€“ implement Minimax manually.
2. **Alpha-Beta Exercise** â€“ show how pruning cuts branches.
3. **Chess Evaluation Discussion** â€“ how to design heuristics.

---

## ðŸ”¹ Summary

* Minimax â†’ optimal play, but slow.
* Alpha-Beta â†’ speeds up search, deeper lookahead.
* Heuristic evaluations â†’ practical for large games.
* Game playing AI balances **optimality vs efficiency**.

---

